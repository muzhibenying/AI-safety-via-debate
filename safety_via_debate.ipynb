{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sklearn.metrics as metrics\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "MNIST_train_dataset = torchvision.datasets.MNIST(root = \"data\", train = True, download = True)\n",
    "MNIST_test_dataset = torchvision.datasets.MNIST(root = \"data\", train = False, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = torch.load(\"data/MNIST/processed/training.pt\")\n",
    "X_test, y_test = torch.load(\"data/MNIST/processed/test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(Dataset):\n",
    "    def __init__(self, train = True, nonzero_pixels = 6):\n",
    "        self.nonzero_pixels = nonzero_pixels\n",
    "        if train == True:\n",
    "            self.X, self.y = X_train, y_train\n",
    "        elif train == False:\n",
    "            self.X, self.y = X_test, y_test\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.X[index]\n",
    "        non_zero_elements = torch.nonzero(image)\n",
    "        mask = torch.zeros(image.shape)\n",
    "        choice_idx = torch.randperm(mask.shape[0])[: self.nonzero_pixels]\n",
    "        samples = non_zero_elements[choice_idx]\n",
    "        mask[samples[:, 0], samples[:, 1]] = 1\n",
    "        image = image - torch.mean(image.float())\n",
    "        image = image / torch.max(image)\n",
    "        masked_image = mask * self.X[index]\n",
    "        label = self.y[index]\n",
    "        input_feature = torch.cat((mask.unsqueeze(0), masked_image.unsqueeze(0)), dim = 0)\n",
    "        return input_feature, masked_image, mask, image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(768.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = MaskedDataset(train = True)\n",
    "test_dataset = MaskedDataset(train = False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 128, shuffle = True)\n",
    "\n",
    "nrows = 2\n",
    "ncols = 5\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 5, figsize = (10, 4))\n",
    "\n",
    "for i, (input_feature, masked_image, mask, image, label) in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        print(mask.sum())\n",
    "        for j, row in enumerate(axs):\n",
    "            for k, ax in enumerate(row):\n",
    "                ax.imshow(mask[j * ncols + k].numpy() + image[j * ncols + k].numpy() * 0.5)\n",
    "                ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Judge(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Judge, self).__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(2, 32, 3),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Conv2d(32, 32, 3),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.MaxPool2d(2),\n",
    "                                         nn.Dropout(p = 0.25))\n",
    "        self.classifier = nn.Sequential(nn.Linear(4608, 10),\n",
    "                                         nn.ReLU(),\n",
    "                                         nn.Dropout(p = 0.25))\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Epoch 0, Loss is 0.01624465174973011\n",
      "At Epoch 0, the accuracy is 0.3078\n",
      "At Epoch 1, Loss is 0.014120508916676044\n",
      "At Epoch 1, the accuracy is 0.39908333333333335\n",
      "At Epoch 2, Loss is 0.013526389375329018\n",
      "At Epoch 2, the accuracy is 0.41983333333333334\n",
      "At Epoch 3, Loss is 0.013288429006934166\n",
      "At Epoch 3, the accuracy is 0.43191666666666667\n",
      "At Epoch 4, Loss is 0.013124302960932255\n",
      "At Epoch 4, the accuracy is 0.4392666666666667\n",
      "At Epoch 5, Loss is 0.013043643906712532\n",
      "At Epoch 5, the accuracy is 0.44283333333333336\n",
      "At Epoch 6, Loss is 0.012973438017070293\n",
      "At Epoch 6, the accuracy is 0.4458166666666667\n",
      "At Epoch 7, Loss is 0.012925321236252785\n",
      "At Epoch 7, the accuracy is 0.4472833333333333\n",
      "At Epoch 8, Loss is 0.01291445642709732\n",
      "At Epoch 8, the accuracy is 0.4465\n",
      "At Epoch 9, Loss is 0.012878306210041046\n",
      "At Epoch 9, the accuracy is 0.4490166666666667\n",
      "At Epoch 10, Loss is 0.01281055249273777\n",
      "At Epoch 10, the accuracy is 0.4508333333333333\n",
      "At Epoch 11, Loss is 0.012785317376255989\n",
      "At Epoch 11, the accuracy is 0.45338333333333336\n",
      "At Epoch 12, Loss is 0.012748447246849537\n",
      "At Epoch 12, the accuracy is 0.45355\n",
      "At Epoch 13, Loss is 0.012739017605781555\n",
      "At Epoch 13, the accuracy is 0.4527333333333333\n",
      "At Epoch 14, Loss is 0.012734903022646904\n",
      "At Epoch 14, the accuracy is 0.4542\n",
      "At Epoch 15, Loss is 0.012700228951871395\n",
      "At Epoch 15, the accuracy is 0.45526666666666665\n",
      "At Epoch 16, Loss is 0.012702926062047482\n",
      "At Epoch 16, the accuracy is 0.45648333333333335\n",
      "At Epoch 17, Loss is 0.012686951085925102\n",
      "At Epoch 17, the accuracy is 0.45516666666666666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-65f91eded359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjudge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-07296498259b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mchoice_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero_pixels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_zero_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "judge = Judge().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(judge.parameters(), lr = 1e-4)\n",
    "for epoch in range(20):\n",
    "    running_loss = 0\n",
    "    outputs = []\n",
    "    labels = []\n",
    "    for i, (input_feature, __, __, image, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = judge(input_feature.cuda())\n",
    "        loss = criterion(output, label.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        outputs.extend(np.argmax(nn.functional.softmax(output, dim = -1).detach().cpu().numpy(), axis = -1))\n",
    "        labels.extend(label.detach().cpu().numpy())\n",
    "    print(\"At Epoch {}, Loss is {}\".format(epoch, running_loss / len(train_loader.dataset)))\n",
    "    outputs = np.array(outputs)\n",
    "    labels = np.array(labels)\n",
    "    print(\"At Epoch {}, the accuracy is {}\".format(epoch, metrics.accuracy_score(outputs, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelDebatePlayer():\n",
    "    def __init__(self, precommit, is_honest):\n",
    "        self.precommit = precommit\n",
    "        self.is_honest = is_honest\n",
    "        self.tree = PixelDebateMCTS()\n",
    "\n",
    "class PixelDebateGame():\n",
    "    def __init__(self, image, judge, player_1, player_2, game_length, rollous_per_move = 10000, seed = 0):\n",
    "        self.image = image\n",
    "        self.judge = judge\n",
    "        self.player_1 = player_1\n",
    "        self.player_2 = player_2\n",
    "        self.game_length = game_length\n",
    "        self.rollouts_per_move = rollouts_per_move\n",
    "        random.seed(seed)\n",
    "    \n",
    "    def other_player(self, player):\n",
    "        return self.player_1 if player == self.player_2 else self.player_2\n",
    "    \n",
    "    def masked_image(self, moves_played):\n",
    "        indices = np.array(moves_played)\n",
    "        xs, ys = indices[:, 0], indices[:, 1]\n",
    "        img = np.zeros(self.images.shape)\n",
    "        img[xs, ys] = self.image[xs, ys]\n",
    "        return img\n",
    "    \n",
    "    def judge_verdict(self, moves_played):\n",
    "        return self.judge(self.masked_image(move_played))\n",
    "    \n",
    "    def winner(self, moves_played):\n",
    "        verdict = self.judge_verdict(moves_played)\n",
    "        \n",
    "        for player in [self.player_1, self.player_2]:\n",
    "            if verict == player.commit or (player.precommit is None and veridict != self.other_player(player).precommit):\n",
    "                return player\n",
    "        return None\n",
    "    def play(self):\n",
    "        moves_played = []\n",
    "        current_player = self.player_1\n",
    "        \n",
    "        for _ in range(6):\n",
    "            state = PixelDebateMCTSNode(\n",
    "                                    game = self,\n",
    "            searcher = current_player,\n",
    "            moves_played = moves_played)\n",
    "            \n",
    "            for _ in range(self.rollouts_per_move):\n",
    "                current_player.tree.choose(state)\n",
    "                \n",
    "            next_state = current_player.tree.choose(state)\n",
    "            moves_played = next_state.moves_played\n",
    "            current_player = state_adversary\n",
    "        return moves_played\n",
    "    \n",
    "def pixelDebateMCTSNode(MCTSNode):\n",
    "    def __init__(self, game, searcher, current_player, moves_played):\n",
    "        \"\"\"\n",
    "        A state of play in the debate game\n",
    "        params:\n",
    "        - game: Description of the current game\n",
    "        - searcher: The player who is performing the search\n",
    "        - current_player: The player whose turn it is to make a move\n",
    "        - moves_played: List of corrdinates that have been played so far\n",
    "        \"\"\"\n",
    "        self.game = game\n",
    "        self.searcher = searcher\n",
    "        self.adversary = game.other_player(searcher)\n",
    "        self.current_player = current_player or searcher\n",
    "        self.moves_played = moves_played\n",
    "        \n",
    "    def find_children(self):\n",
    "        \"\"\"\n",
    "        All possible successor of this board state.\n",
    "        \"\"\"\n",
    "        next_player = self.game.other_player(self.current_player)\n",
    "        \n",
    "        return {PixelDebateMCTSNode(self.game, self.searcher, next_player, self.moves_played + [tuple(coord),] for coord in np.argwhere(self.game.image) if tuple(coord) not in self.moves_played)}\n",
    "    \n",
    "    def find_random_child(self):\n",
    "        \"\"\"\n",
    "        Random successor of this board state (for more efficient simulation)\n",
    "        \"\"\"\n",
    "        if self.is_terminal():\n",
    "            return None\n",
    "        return random.choice(list(self.find_children()))\n",
    "    \n",
    "    def is_terminal(self):\n",
    "        return len(self.moves_played) >= self.game.game_length\n",
    "    \n",
    "    def reward(self):\n",
    "        \"\"\"\n",
    "        Assume self is terminal node. 1 = win, 0 = loss, .5 = tie, etc.\n",
    "        \"\"\"\n",
    "        winner = self.game.winner(self.moves_played)\n",
    "        if winner = self.searcher:\n",
    "            return 1\n",
    "        if winner = self.adversary:\n",
    "            return 0\n",
    "        return 0.5\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \"\"\"\n",
    "        Nodes must be hashable\n",
    "        \"\"\"\n",
    "        coords = sorted(self.moves_played)\n",
    "        return hash(str(coords))\n",
    "    \n",
    "    def __eq__(node1, node2):\n",
    "        \"\"\"\n",
    "        Nodes must be comparable\n",
    "        \"\"\"\n",
    "        return set(node1.moves_played) == set(node_2.moves_played) and node1.game == node2.game\n",
    "\n",
    "class PixelDebateMCTS(MCTS):\n",
    "    def __select_decendent(self, node):\n",
    "        def U(n):\n",
    "            p = 1.0 / np.sum(n.game.image > 0)\n",
    "            child_visit = sum([self.N[c] for c in self.children.get(n, [])])\n",
    "        \n",
    "        def puct(n):\n",
    "            return self.Q[n] + U(n)\n",
    "        \n",
    "        return max(self.children[node], key = puct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
